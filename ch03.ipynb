{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    model_selection,    \n",
    "    preprocessing,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from yellowbrick.classifier import (\n",
    "    ConfusionMatrix,\n",
    "    ROCAUC,\n",
    ")\n",
    "from yellowbrick.model_selection import (\n",
    "    LearningCurve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"https://biostat.app.vumc.org/\"\n",
    "    \"wiki/pub/Main/DataSets/titanic3.xls\"\n",
    ")\n",
    "df = pd.read_excel(url)\n",
    "orig_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass         int64\n",
       "survived       int64\n",
       "name          object\n",
       "sex           object\n",
       "age          float64\n",
       "sibsp          int64\n",
       "parch          int64\n",
       "ticket        object\n",
       "fare         float64\n",
       "cabin         object\n",
       "embarked      object\n",
       "boat          object\n",
       "body         float64\n",
       "home.dest     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas_profiling\n",
    "#pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass     survived\n",
       "count  1309.000000  1309.000000\n",
       "mean      2.294882     0.381971\n",
       "std       0.837836     0.486055\n",
       "min       1.000000     0.000000\n",
       "25%       2.000000     0.000000\n",
       "50%       3.000000     0.000000\n",
       "75%       3.000000     1.000000\n",
       "max       3.000000     1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "survived        0\n",
       "name            0\n",
       "sex             0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "cabin        1014\n",
       "embarked        2\n",
       "boat          823\n",
       "body         1188\n",
       "home.dest     564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     2\n",
       "3     1\n",
       "4     2\n",
       "5     1\n",
       "6     1\n",
       "7     2\n",
       "8     1\n",
       "9     2\n",
       "10    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=1).loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.head()  # rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3    135.0\n",
       "4      NaN\n",
       "Name: body, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[mask].body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      843\n",
       "female    466\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sex.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S      914\n",
       "C      270\n",
       "Q      123\n",
       "NaN      2\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Allen, Miss. Elisabeth Walton\n",
       "1    Allison, Master. Hudson Trevor\n",
       "2      Allison, Miss. Helen Loraine\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = df.name\n",
    "name.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"name\",\n",
    "        \"ticket\",\n",
    "        \"home.dest\",\n",
    "        \"boat\",\n",
    "        \"body\",\n",
    "        \"cabin\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'survived', 'age', 'sibsp', 'parch', 'fare', 'sex_female',\n",
       "       'sex_male', 'embarked_C', 'embarked_Q', 'embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"sex_male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'survived', 'age', 'sibsp', 'parch', 'fare', 'sex_female',\n",
       "       'embarked_C', 'embarked_Q', 'embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.survived\n",
    "X = df.drop(columns=\"survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/janitor/utils.py:263: FutureWarning: get_features_targets() has moved. Please use ml.get_features_targets().\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import janitor as jn\n",
    "X, y = jn.get_features_targets(\n",
    "    df, target_columns=\"survived\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_female', 'embarked_C',\n",
       "       'embarked_Q', 'embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import (\n",
    "    enable_iterative_imputer,\n",
    ")\n",
    "from sklearn import impute\n",
    "num_cols = [\n",
    "    \"pclass\",\n",
    "    \"age\",\n",
    "    \"sibsp\",\n",
    "    \"parch\",\n",
    "    \"fare\",\n",
    "    \"sex_female\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = impute.IterativeImputer()\n",
    "imputed = imputer.fit_transform(\n",
    "    X_train[num_cols]\n",
    ")\n",
    "X_train.loc[:, num_cols] = imputed\n",
    "imputed = imputer.transform(X_test[num_cols])\n",
    "X_test.loc[:, num_cols] = imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "meds = X_train.median()\n",
    "X_train = X_train.fillna(meds)\n",
    "X_test = X_test.fillna(meds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "cols = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_female', 'embarked_C',\n",
    "   'embarked_Q', 'embarked_S']\n",
    "sca = preprocessing.StandardScaler()\n",
    "X_train = sca.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = sca.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tweak_titanic(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"ticket\",\n",
    "            \"home.dest\",\n",
    "            \"boat\",\n",
    "            \"body\",\n",
    "            \"cabin\",\n",
    "        ]\n",
    "    ).pipe(pd.get_dummies, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_X_y(\n",
    "    df, y_col, size=0.3, std_cols=None\n",
    "):\n",
    "    y = df[y_col]\n",
    "    X = df.drop(columns=y_col)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=size, random_state=42\n",
    "    )\n",
    "    cols = X.columns\n",
    "    num_cols = [\n",
    "        \"pclass\",\n",
    "        \"age\",\n",
    "        \"sibsp\",\n",
    "        \"parch\",\n",
    "        \"fare\",\n",
    "    ]\n",
    "    fi = impute.IterativeImputer()\n",
    "    fitted = fi.fit_transform(X_train[num_cols])\n",
    "    X_train = X_train.assign(**{c:fitted[:,i] for i, c in enumerate(num_cols)})\n",
    "    test_fit = fi.transform(X_test[num_cols])\n",
    "    X_test = X_test.assign(**{c:test_fit[:,i] for i, c in enumerate(num_cols)})\n",
    "    if std_cols:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        fitted = std.fit_transform(X_train[std_cols])\n",
    "        X_train = X_train.assign(**{c:fitted[:,i] for i, c in enumerate(std_cols)})\n",
    "        test_fit = std.transform(X_test[std_cols])\n",
    "        X_test = X_test.assign(**{c:test_fit[:,i] for i, c in enumerate(std_cols)})\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_df = tweak_titanic(orig_df)\n",
    "std_cols = \"pclass,age,sibsp,fare\".split(\",\")\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(\n",
    "    ti_df, \"survived\", std_cols=std_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5699745547073791"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "bm = DummyClassifier()\n",
    "bm.fit(X_train, y_train)\n",
    "bm.score(X_test, y_test)  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.precision_score(\n",
    "    y_test, bm.predict(X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import (\n",
    "    KNeighborsClassifier,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m [\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=1'>2</a>\u001b[0m     DummyClassifier,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=2'>3</a>\u001b[0m     LogisticRegression,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=8'>9</a>\u001b[0m     xgboost\u001b[39m.\u001b[39mXGBClassifier,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=9'>10</a>\u001b[0m ]:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m model()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=11'>12</a>\u001b[0m     kfold \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39;49mKFold(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=12'>13</a>\u001b[0m         n_splits\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=13'>14</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=14'>15</a>\u001b[0m     s \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39mcross_val_score(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=15'>16</a>\u001b[0m         \u001b[39mcls\u001b[39m, X, y, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m\"\u001b[39m, cv\u001b[39m=\u001b[39mkfold\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=16'>17</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=18'>19</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m22\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m  AUC: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=19'>20</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m STD: \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39mstd()\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/mnt/d/gui/Livro_Machine_Learning_Harrison/ch03.ipynb#ch0000034vscode-remote?line=20'>21</a>\u001b[0m     )\n",
      "File \u001b[0;32m/home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py:435\u001b[0m, in \u001b[0;36mKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=433'>434</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m*\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=434'>435</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(n_splits\u001b[39m=\u001b[39;49mn_splits, shuffle\u001b[39m=\u001b[39;49mshuffle, random_state\u001b[39m=\u001b[39;49mrandom_state)\n",
      "File \u001b[0;32m/home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py:296\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=292'>293</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mshuffle must be True or False; got \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shuffle))\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=294'>295</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shuffle \u001b[39mand\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# None is the default\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=295'>296</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=296'>297</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSetting a random_state has no effect since shuffle is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=297'>298</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFalse. You should leave \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=298'>299</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrandom_state to its default (None), or set shuffle=True.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=299'>300</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=301'>302</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m=\u001b[39m n_splits\n\u001b[1;32m    <a href='file:///home/gui/anaconda3/envs/mlharrison/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=302'>303</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshuffle \u001b[39m=\u001b[39m shuffle\n",
      "\u001b[0;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "for model in [\n",
    "    DummyClassifier,\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    GaussianNB,\n",
    "    SVC,\n",
    "    RandomForestClassifier,\n",
    "    xgboost.XGBClassifier,\n",
    "]:\n",
    "    cls = model()\n",
    "    kfold = model_selection.KFold(\n",
    "        n_splits=10, random_state=42\n",
    "    )\n",
    "    s = model_selection.cross_val_score(\n",
    "        cls, X, y, scoring=\"roc_auc\", cv=kfold\n",
    "    )\n",
    "    print(\n",
    "        f\"{model.__name__:22}  AUC: \"\n",
    "        f\"{s.mean():.3f} STD: {s.std():.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import (\n",
    "    StackingClassifier,\n",
    ")\n",
    "clfs = [\n",
    "    x()\n",
    "    for x in [\n",
    "        LogisticRegression,\n",
    "        DecisionTreeClassifier,\n",
    "        KNeighborsClassifier,\n",
    "        GaussianNB,\n",
    "        SVC,\n",
    "        RandomForestClassifier,\n",
    "    ]\n",
    "]\n",
    "stack = StackingClassifier(\n",
    "    classifiers=clfs,\n",
    "    meta_classifier=LogisticRegression(),\n",
    ")\n",
    "kfold = model_selection.KFold(\n",
    "    n_splits=10, random_state=42\n",
    ")\n",
    "s = model_selection.cross_val_score(\n",
    "    stack, X, y, scoring=\"roc_auc\", cv=kfold\n",
    ")\n",
    "print(\n",
    "    f\"{stack.__class__.__name__}  \"\n",
    "    f\"AUC: {s.mean():.3f}  STD: {s.std():.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100, random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(\n",
    "    y_test, rf.predict(X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for col, val in sorted(\n",
    "    zip(\n",
    "        X_train.columns,\n",
    "        rf.feature_importances_,\n",
    "    ),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True,\n",
    ")[:5]:\n",
    "    print(f\"{col:10}{val:10.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4 = ensemble.RandomForestClassifier()\n",
    "params = {\n",
    "    \"max_features\": [0.4, \"auto\"],\n",
    "    \"n_estimators\": [15, 200],\n",
    "    \"min_samples_leaf\": [1, 0.1],\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "cv = model_selection.GridSearchCV(\n",
    "    rf4, params, n_jobs=-1\n",
    ").fit(X_train, y_train)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf5 = ensemble.RandomForestClassifier(\n",
    "    **{\n",
    "        \"max_features\": \"auto\",\n",
    "        \"min_samples_leaf\": 0.1,\n",
    "        \"n_estimators\": 200,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    ")\n",
    "rf5.fit(X_train, y_train)\n",
    "rf5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = rf5.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"died\", 1: \"survived\"}\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cm_viz = ConfusionMatrix(\n",
    "    rf5,\n",
    "    classes=[\"died\", \"survived\"],\n",
    "    label_encoder=mapping,\n",
    ")\n",
    "cm_viz.score(X_test, y_test)\n",
    "cm_viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf5.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "roc_viz = ROCAUC(rf5)\n",
    "roc_viz.score(X_test, y_test)\n",
    "roc_viz.poof()\n",
    "#fig.savefig(\"images/mlpr_0305.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "cv = StratifiedKFold(12)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "lc_viz = LearningCurve(\n",
    "    rf5,\n",
    "    cv=cv,\n",
    "    train_sizes=sizes,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=4,\n",
    "    ax=ax,\n",
    ")\n",
    "lc_viz.fit(X, y)\n",
    "lc_viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pic = pickle.dumps(rf5)\n",
    "rf6 = pickle.loads(pic)\n",
    "y_pred = rf6.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
